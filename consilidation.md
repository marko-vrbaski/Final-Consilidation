Exit Ticket Reflection
The completion of Marwick's lithic analysis data replication assignment represents my most important accomplishment from this course. The assignment caught my attention because it showed my ability to recognize the difference between simply reproducing something and being able to actually replicate it. The experience showed me how digital archaeology relates to computer science through unexpected connections. 
The Week 11 line serves as my reference point to develop this reflection because it demonstrated how archaeological knowledge value affects scientific credibility through result replicability. 
“The value of new archaeological knowledge is strongly determined by how credible it is, and a key measure of scientific credibility is how replicable new results are.”
The statement became memorable to me because it holds equal value for computer science as it does for archaeology.

Redoing My "Most Impressive" Work: Replication of Marwick’s Analysis
I initially approached the Tham Lod and Ban Rai dataset analysis as if it were a lab demonstration. The analysis of data followed these steps: I imported CSV files to create boxplots and calculate proportions which confirmed Loiselle's findings against Marwick's theoretical models. My main objective at that time focused on achieving code execution. I understand this task differently because I now understand how each step in the process adds value. I failed to understand the importance of documentation and decision-making processes when I first started my coursework. The third week of the course showed that researchers actively create data through deliberate selection methods instead of finding it in its natural state. I wrote: “The dataset is built step by step from decisions about what we notice and what we record.” I failed to use this mindset during my first attempt at replication
Doing the lithic analysis again I now payed attention to every moment when a subjective decision sneaks into the workflow. For example, how …
•	missing values in the “DORSAL_COR” column get interpreted
•	grouping by site collapses meaningful spatial variation
•	data cleaning affects the patterns we think we “discover”
This shift mirrors the lesson I learned from the Campbell glass dataset:

Redoing the same computation now feels less like checking if my code runs and more like checking if the interpretation holds up once I understand the weaknesses of the dataset and the decisions inside the pipeline.
The change follows the lesson I discovered from analyzing the Campbell glass dataset which states:
“Data does not just exist; the data is maintained… mediated through technical systems that need human decisions at each step.” 
Redoing the computation process now focuses on checking how well the results and interpretation match each other instead of checking the code execution due to now understanding the weaknesses of the dataset limits and pipeline selection points.

Reproducing vs. Replicating: What I Now Understand
I approached all assignments with the mindset of reproduction during the initial part of the course. If the code would run and the output looked similar enough, I thought I understood the problem. Now I know the difference:
Reproducing
Getting the same output by following someone else’s instructions.
This was my initial working mindset.
Replicating
I need to determine if the conclusion remains valid when I perform the process using my personal judgment for cleaning decisions and various computational settings.
The purpose of replication goes beyond confirming the original findings because it tests how well the findings withstand different conditions.  And this is where digital archaeology suddenly felt very similar to CS.
In the Week 8 consolidation I wrote that models “reveal the measurements we select to analyze,” not the “truth” behind the data. 
The principle directly applies to the process of replication. It forces you to confront the assumptions you want to hide.

Why Replication Matters in Digital Archaeology
The main theme from my previous research continued to appear because digital archaeology requires proof of data origin rather than possessing data itself.
For the Week 4 work, while counting graveyard materials I realized how easy it is for whole groups of people to disappear from datasets because the database can’t hold irregularities. I wrote:
“The absence of weathered stones and unmarked graves… creates a narrative that speaks to their existence.” 
Replication is what uncovers these gaps.
It is also critical because archaeology has multiple audiences:
-	Scholars, who want transparency
-	Descendant communities who want respectful handling of memory
-	The public who encounters simplified versions of the past
As I wrote in Week 2, even the process of classifying a cross-topped pillar needs ethical evaluation because it will decide how people in the future will understand that historical community.
The process of replication requires us to demonstrate our interpretation methods so that audiences can hold us accountable.

How My Thinking Has Changed Since Module 2
At the end of Module 2 I still thought digital archaeology was mainly a technical skill. I was focused on running models correctly and producing clean outputs. Shown in Week 8 where I wrote:
“I used to force all data points into organized categories without allowing irregular data to teach me anything.” 
Now my thinking has changed in three big ways:
1. I no longer trust “clean” datasets
Most of the important stories are in the irregularities.
This connects all the way back to the DEBS cemetery work where unusual grave markers refused to fit into neat categories. 
2. I see code as part of the interpretation
In Week 11 I wrote that running code “felt like feature extraction,” which helped me see that choices in CS are choices in archaeology too. 
3. I now document uncertainty instead of hiding it
I used to view absent data as a defect in my work. The missing data segment has become vital to understand the entire story.
The feedback I received matches exactly what I attempted to incorporate into my work which includes showing my step-by-step process and connecting my personal experiences to academic readings and demonstrating my problem-solving methods. I returned to that feedback during Week 8.:
“I need to establish direct connections between my thoughts and the reading materials.” 

New Dilemmas That Emerged
All of this introduced new questions that I am still working through:
•	If every dataset is the product of interpretation, how do we avoid reinforcing existing power structures? (A problem I saw in Week 5: standardized schemas erase cultural specificity. )
•	How much of our code should be shown to the public, and how do we explain it in a way that is meaningful to non-technical audiences?
•	In CS, convenience often wins over transparency. In archaeology, that tradeoff can erase people and stories. How do we balance speed with responsibility?
These dilemmas feel more complicated than before, but they also show how much my thinking has expanded.
I am currently thinking about three new questions which need to be answered.
-	If all datasets are products of interpretation, how would we avoid creating barriers that support current power systems? A problem I noticed in Week 5 standardized schemas that demonstrates how they eliminate unique cultural elements from data.
-	The exact amount of code which should be visible to the public, and how to create methods that translate complex technical information for non-technical people to understand?
-	The trade between convenience and transparency in CS leads to different results than in archaeology because archaeology loses its human and narrative content. How should speed be balanced with responsibility?
The new dilemmas I face feel more complicated than before, but also demonstrate my increasing understanding.

Final Thoughts
Looking back across my journals, errors, wins, and missteps, the biggest difference is that I now understand that digital archaeology is the practice of revealing the hidden work behind data. Whether I am working with graveyard maps or with topic models or ADS datasets or lithic analysis scripts, the core task is the same:
•	show your process
•	document the decisions
•	expose your uncertainties
•	and then let others test the claim for themselves
Replication is the mechanism that makes this possible.
My earlier work in the class was focused on making things “work.”
My later work is now focused on making things visible. That feels like real progress.
